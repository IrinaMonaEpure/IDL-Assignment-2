{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group52_IDL_Assignment2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndAj6Q0AJtkJ"
      },
      "source": [
        "#Task 1: Learning the Basics of Keras and TensorFlow\n",
        "#MLPs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwDKFr5vWev8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrizKKZpXRoi"
      },
      "source": [
        "We will experiment with different MLPs for performing classification on datasets MNIST and Fashion MNIST. These datasets are loaded in the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTUnPHs-XyB1",
        "outputId": "c9fd1322-d09a-446b-dd1f-f00acf5ea63d"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# MNIST\n",
        "#mnist = fetch_openml('mnist_784', version=1)\n",
        "#X_mnist, y_mnist = mnist[\"data\"], mnist[\"target\"]\n",
        "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n",
        "# labels are strings, so we need to cast y to integers\n",
        "X_train_mnist = X_train_mnist.reshape(60000, 784)\n",
        "print(X_train_mnist)\n",
        "X_test_mnist = X_test_mnist.reshape(10000, 784)\n",
        "X_train_mnist = X_train_mnist.astype('float32')\n",
        "X_test_mnist = X_test_mnist.astype('float32')\n",
        "X_train_mnist /= 255\n",
        "X_test_mnist /= 255\n",
        "print(X_train_mnist.shape[0], 'train samples')\n",
        "print(X_test_mnist.shape[0], 'test samples')\n",
        "# create train, validation, and test sets and scale the input features down to the [0,1] range\n",
        "X_valid_mnist, X_train_mnist = X_train_mnist[:5000], X_train_mnist[5000:]\n",
        "y_valid_mnist, y_train_mnist = y_train_mnist[:5000], y_train_mnist[5000:]\n",
        "print(\"Shape of train set data\", X_train_mnist[0].shape)\n",
        "print(\"Datatype of train set data\", X_train_mnist[0].dtype)\n",
        "\n",
        "# Fashion MNIST\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full_fashion, y_train_full_fashion), (X_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
        "# create a validation set and scale the input features down to the [0,1] range\n",
        "X_valid_fashion, X_train_fashion = X_train_full_fashion[:5000] / 255.0, X_train_full_fashion[5000:] / 255.0\n",
        "y_valid_fashion, y_train_fashion = y_train_full_fashion[:5000], y_train_full_fashion[5000:]\n",
        "X_test_fashion = X_test_fashion / 255.0\n",
        "print(\"Shape of train set data\", X_train_full_fashion.shape)\n",
        "print(\"Datatype of train set data\", X_train_full_fashion.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Shape of train set data (784,)\n",
            "Datatype of train set data float32\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "Shape of train set data (60000, 28, 28)\n",
            "Datatype of train set data uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SnHRfy8vXyn"
      },
      "source": [
        "Next, we're going to create a wrapper class for the reference MLP network from Aurelien Geron, \"Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow\", Ch. 10, pp. 297-307. This is done in order to avoid having to repeat hyperparameter values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWX5wAlzw2mz"
      },
      "source": [
        "class ReferenceMLP:\n",
        "\n",
        "\n",
        "  # The default hyperparameter values correspond to the refernce network\n",
        "  def __init__(self, flatten=True, kernel_initializer=None, bias_initializer=None,\n",
        "               hidden_layers_activation=\"relu\", kernel_regularizer=None,\n",
        "               bias_regularizer=None, activity_regularizer=None,\n",
        "               dropout_rate=None, hidden_layers_number=2,\n",
        "               hidden_layers_dropout=[], hidden_layers_sizes=[300, 100]):\n",
        "    \n",
        "    # Create a Sequential model\n",
        "    self.model = keras.models.Sequential()\n",
        "\n",
        "    # Only Fashion MNIST needs flattening\n",
        "    if flatten:\n",
        "      # Convert each input into a 1D array with a Flatten layer\n",
        "      self.model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "\n",
        "    # Add hidden layers according to the specifications\n",
        "    for i in range(hidden_layers_number):\n",
        "        # Some layers may be Dropout layers\n",
        "        if i in hidden_layers_dropout:\n",
        "          self.model.add(keras.layers.Dropout(dropout_rate))\n",
        "        # All others are Dense layers\n",
        "        else:\n",
        "          self.model.add(keras.layers.Dense(\n",
        "              hidden_layers_sizes[i],\n",
        "              input_shape=(784,), \n",
        "              activation=hidden_layers_activation,\n",
        "              kernel_initializer=kernel_initializer,\n",
        "              bias_initializer=bias_initializer,\n",
        "              kernel_regularizer=kernel_regularizer,\n",
        "              bias_regularizer=bias_regularizer,\n",
        "              activity_regularizer=activity_regularizer))\n",
        "\n",
        "    # Add the output layer with 10 nodes and softmax activation\n",
        "    self.model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "  # Compilation hyperparameters can be changed to experiment with different\n",
        "  # optimization algorithms\n",
        "  def compile(self, optimizer=\"sgd\", steps_per_execution=None):\n",
        "    self.model.compile(optimizer=optimizer,\n",
        "                       steps_per_execution=steps_per_execution,\n",
        "                       loss=\"sparse_categorical_crossentropy\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "    \n",
        "\n",
        "  # Fits the network with data from either dataset\n",
        "  def fit(self, X_train, y_train, X_valid, y_valid):\n",
        "    self.model.fit(X_train, y_train, epochs=1,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "    \n",
        "\n",
        "  # Evaluates the network on the test set  \n",
        "  def evaluate(self, X_test, y_test):\n",
        "    return self.model.evaluate(X_test, y_test)\n",
        "\n",
        "  # Fit and evaluate with a certain dataset (to avoid writing the same code\n",
        "  # over and over)\n",
        "  def fit_evaluate(self, dataset):\n",
        "    if dataset=='mnist':\n",
        "      self.fit(X_train_mnist, y_train_mnist, X_valid_mnist, y_valid_mnist)\n",
        "      return self.evaluate(X_test_mnist, y_test_mnist)\n",
        "    else:\n",
        "      self.fit(X_train_fashion, y_train_fashion, X_valid_fashion,\n",
        "               y_valid_fashion)\n",
        "      return self.evaluate(X_test_fashion, y_test_fashion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tp8QdDYJHcf"
      },
      "source": [
        "We need to create some lists of the hyperparameter values that we want to try. This will make it easy to parse through them in our experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTfSl3CJJXmA"
      },
      "source": [
        "initializers = [None, 'random_normal', 'random_uniform', 'truncated_normal', 'zeros',\n",
        "                'ones']\n",
        "activations = ['relu', 'sigmoid', 'tanh', 'selu', 'elu', 'exponential']\n",
        "regularizers = [None, 'l1', 'l2']\n",
        "optimizers = ['adadelta', 'adagrad', 'adam', 'adamax', 'ftrl', 'nadam',\n",
        "              'rmsprop', 'sgd']\n",
        "steps_per_executions = [None, 2, 5, 10, 20, 50, 100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwFqiE4SOMCi"
      },
      "source": [
        "Now we iterate over these lists and observe the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "8mtnobMSXld1",
        "outputId": "9f105092-330b-4c9f-c26d-8344f72f0a4c"
      },
      "source": [
        "# Accuracy and loss values will be saved in these dictionaries\n",
        "initializer_dict, activation_dict, regularizer_dict, optimizer_dict, steps_dict = {}, {}, {}, {}, {}\n",
        "\n",
        "# Take each dataset in turn\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  print(dataset)\n",
        "\n",
        "  #Loop over selected values for each hyperparameter\n",
        "  \n",
        "  for i in initializers:\n",
        "    print(i)\n",
        "    net = ReferenceMLP(flatten=(dataset=='fashion'), kernel_initializer=i, bias_initializer=i)\n",
        "    net.compile()\n",
        "    initializer_dict[(dataset, i)] = net.fit_evaluate(dataset)\n",
        "    del net\n",
        "  \n",
        "  for i in activations:\n",
        "    print(i)\n",
        "    net = ReferenceMLP(flatten=(dataset=='fashion'), hidden_layers_activation=i)\n",
        "    net.compile()\n",
        "    activation_dict[(dataset, i)] = net.fit_evaluate(dataset)\n",
        "    del net\n",
        "  \n",
        "\n",
        "  for i in regularizers:\n",
        "    print(i)\n",
        "    net = ReferenceMLP(flatten=(dataset=='fashion'), kernel_regularizer=i,\n",
        "                       bias_regularizer=i, activity_regularizer=i)\n",
        "    net.compile()\n",
        "    regularizer_dict[(dataset, i)] = net.fit_evaluate(dataset)\n",
        "    del net\n",
        "\n",
        "  for i in optimizers:\n",
        "    print(i)\n",
        "    net = ReferenceMLP(flatten=(dataset=='fashion'))\n",
        "    net.compile(optimizer=i)\n",
        "    optimizer_dict[(dataset, i)] = net.fit_evaluate(dataset)\n",
        "    del net\n",
        "\n",
        "  for i in steps_per_executions:\n",
        "    print(i)\n",
        "    net = ReferenceMLP(flatten=(dataset=='fashion'))\n",
        "    net.compile(steps_per_execution=i)\n",
        "    steps_dict[(dataset, i)] = net.fit_evaluate(dataset)\n",
        "    del net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist\n",
            "None\n",
            "1711/1719 [============================>.] - ETA: 0s - loss: 0.6233 - accuracy: 0.8368"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b44b04947206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReferenceMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'fashion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0minitializer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-30e601bbc99c>\u001b[0m in \u001b[0;36mfit_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_mnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_mnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-30e601bbc99c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     self.model.fit(X_train, y_train, epochs=1,\n\u001b[0;32m---> 52\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1261\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1264\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1248\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4063\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4064\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 4065\u001b[0;31m         _ctx, \"Identity\", name, input)\n\u001b[0m\u001b[1;32m   4066\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4067\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Y5dWFQMvwB"
      },
      "source": [
        "Time to view the results of our experiments with these hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le_xHPpmM00Y",
        "outputId": "6eb03ea9-d240-42c9-e08f-8743106ac691"
      },
      "source": [
        "print(\"Kernel, and bias initializers: \")\n",
        "print(initializer_dict)\n",
        "print(\"Hidden layer activation functions: \")\n",
        "print(activation_dict)\n",
        "print(\"Kernel, bias, and activity regularizers: \")\n",
        "print(regularizer_dict)\n",
        "print(\"Optimizers: \")\n",
        "print(optimizer_dict)\n",
        "print(\"Steps per execution: \")\n",
        "print(steps_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel, and bias initializers: \n",
            "{('mnist', None): [0.3114880323410034, 0.9139000177383423], ('mnist', 'random_normal'): [0.32399439811706543, 0.9097999930381775], ('mnist', 'random_uniform'): [0.35385939478874207, 0.9003000259399414], ('mnist', 'truncated_normal'): [0.3310825824737549, 0.9056000113487244], ('mnist', 'zeros'): [2.30111026763916, 0.11349999904632568], ('mnist', 'ones'): [2.3011059761047363, 0.11349999904632568], ('fashion', None): [0.5580259561538696, 0.8023999929428101], ('fashion', 'random_normal'): [0.5473095178604126, 0.8125], ('fashion', 'random_uniform'): [0.6123326420783997, 0.7879999876022339], ('fashion', 'truncated_normal'): [0.5661210417747498, 0.7997999787330627], ('fashion', 'zeros'): [2.3026182651519775, 0.10000000149011612], ('fashion', 'ones'): [2.302612543106079, 0.10000000149011612]}\n",
            "Hidden layer activation functions: \n",
            "{('mnist', 'relu'): [0.3154290020465851, 0.9096999764442444], ('mnist', 'sigmoid'): [1.9444007873535156, 0.6186000108718872], ('mnist', 'tanh'): [0.3302043080329895, 0.9079999923706055], ('mnist', 'selu'): [0.29451853036880493, 0.9153000116348267], ('mnist', 'elu'): [0.32289424538612366, 0.90829998254776], ('mnist', 'exponential'): [nan, 0.09799999743700027], ('fashion', 'relu'): [0.5434632897377014, 0.8115000128746033], ('fashion', 'sigmoid'): [1.5123555660247803, 0.6026999950408936], ('fashion', 'tanh'): [0.5271571278572083, 0.8138999938964844], ('fashion', 'selu'): [0.49449121952056885, 0.8226000070571899], ('fashion', 'elu'): [0.5293673872947693, 0.8133000135421753], ('fashion', 'exponential'): [nan, 0.10000000149011612]}\n",
            "Kernel, bias, and activity regularizers: \n",
            "{('mnist', None): [0.3135697543621063, 0.9128999710083008], ('mnist', 'l1'): [2.341222047805786, 0.21719999611377716], ('mnist', 'l2'): [3.733198881149292, 0.9092000126838684], ('fashion', None): [0.5497739911079407, 0.8025000095367432], ('fashion', 'l1'): [1.9013923406600952, 0.5472999811172485], ('fashion', 'l2'): [3.896375894546509, 0.8055999875068665]}\n",
            "Optimizers: \n",
            "{('mnist', 'adadelta'): [2.116866111755371, 0.27160000801086426], ('mnist', 'adagrad'): [0.5943590998649597, 0.8668000102043152], ('mnist', 'adam'): [0.11638778448104858, 0.9610000252723694], ('mnist', 'adamax'): [0.16752028465270996, 0.95169997215271], ('mnist', 'ftrl'): [2.3022348880767822, 0.11349999904632568], ('mnist', 'nadam'): [0.10438305884599686, 0.9677000045776367], ('mnist', 'rmsprop'): [0.10500895977020264, 0.9661999940872192], ('mnist', 'sgd'): [0.3124457895755768, 0.9103999733924866], ('fashion', 'adadelta'): [1.8043075799942017, 0.522599995136261], ('fashion', 'adagrad'): [0.7418915629386902, 0.7498000264167786], ('fashion', 'adam'): [0.4445517957210541, 0.8396000266075134], ('fashion', 'adamax'): [0.4440191984176636, 0.8420000076293945], ('fashion', 'ftrl'): [2.302586317062378, 0.10000000149011612], ('fashion', 'nadam'): [0.4415721595287323, 0.847599983215332], ('fashion', 'rmsprop'): [0.4309372007846832, 0.8468000292778015], ('fashion', 'sgd'): [0.5674023628234863, 0.7985000014305115]}\n",
            "Steps per execution: \n",
            "{('mnist', None): [0.32103756070137024, 0.9077000021934509], ('mnist', 2): [0.31068599224090576, 0.911300003528595], ('mnist', 5): [0.3021520674228668, 0.9147999882698059], ('mnist', 10): [0.3044549822807312, 0.9162999987602234], ('mnist', 20): [0.31340330839157104, 0.9111999869346619], ('mnist', 50): [0.30891624093055725, 0.9146000146865845], ('mnist', 100): [0.3049001097679138, 0.9154999852180481], ('fashion', None): [0.5343309640884399, 0.8158000111579895], ('fashion', 2): [0.5349324941635132, 0.8090999722480774], ('fashion', 5): [0.5416889786720276, 0.8125], ('fashion', 10): [0.5347653031349182, 0.8109999895095825], ('fashion', 20): [0.5285729765892029, 0.8198000192642212], ('fashion', 50): [0.5545006990432739, 0.8003000020980835], ('fashion', 100): [0.5368165373802185, 0.8141999840736389]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKtpDFBZPaNa"
      },
      "source": [
        "Our final experiments involve changing the overall architecture of the network. This includes: changing the layers' sizes, adding or removing layers, and using Dropout layers for regularization. In the code cell below, we attempt a varied range of architectures. This experiment requires more thought than simply looping over values for a hyperparameters, so we'll manually tweak the architectures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYgpnXPdQ6hh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "c5125b48-ad1e-4da1-8e7c-d6821a7d39a7"
      },
      "source": [
        "# First, we'll observe the difference in performance after adding Dropout layers\n",
        "# after every Dense layer\n",
        "\n",
        "# Dictionary for saving the experiment results\n",
        "architecture_dict = {}\n",
        "\n",
        "# First, let's see the performance of the reference model\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  reference_net = ReferenceMLP(flatten=(dataset=='fashion'))\n",
        "  reference_net.compile()\n",
        "  architecture_dict[\"reference network \" + dataset] = reference_net.fit_evaluate(dataset)\n",
        "\n",
        "# Now we can add Dropout layers and see the result\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  do_net = ReferenceMLP(flatten=(dataset=='fashion'), dropout_rate=0.5,\n",
        "                               hidden_layers_number=4, hidden_layers_dropout=[1, 3],\n",
        "                               hidden_layers_sizes=[300, None, 100, None])\n",
        "  do_net.compile()\n",
        "  architecture_dict[\"reference network with dropout \" + dataset] = do_net.fit_evaluate(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1645/1719 [===========================>..] - ETA: 0s - loss: 0.6387 - accuracy: 0.8349"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-57b9e37f1faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mreference_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReferenceMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'fashion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mreference_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0marchitecture_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reference network \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Now we can add Dropout layers and see the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-30e601bbc99c>\u001b[0m in \u001b[0;36mfit_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_mnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_mnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-30e601bbc99c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     self.model.fit(X_train, y_train, epochs=1,\n\u001b[0;32m---> 52\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofmPKIfKW9Na",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3d9000-5c77-499d-e587-ddf0b62b0c4f"
      },
      "source": [
        "# Now, we'd like to see how the layers' sizes affect the performance\n",
        "\n",
        "# First, we decrease the sizes\n",
        "for dataset in ['fashion']:\n",
        "  dec_size_net = ReferenceMLP(flatten=(dataset=='fashion'),\n",
        "                              hidden_layers_sizes=[100, 50])\n",
        "  dec_size_net.compile()\n",
        "  architecture_dict[\"decreased layer size network \" + dataset] = dec_size_net.fit_evaluate(dataset)\n",
        "\n",
        "# And then we increase it\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  inc_size_net = ReferenceMLP(flatten=(dataset=='fashion'),\n",
        "                              hidden_layers_sizes=[500, 200])\n",
        "  inc_size_net.compile()\n",
        "  architecture_dict[\"increased layer size network \" + dataset] = inc_size_net.fit_evaluate(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.7750 - accuracy: 0.7451 - val_loss: 0.5404 - val_accuracy: 0.8190\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5753 - accuracy: 0.8025\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5862 - accuracy: 0.8503 - val_loss: 0.3158 - val_accuracy: 0.9112\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3216 - accuracy: 0.9053\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6942 - accuracy: 0.7725 - val_loss: 0.5109 - val_accuracy: 0.8308\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5487 - accuracy: 0.8093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTe36LWzZhdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d1aa85-8998-4eb6-88a9-22461819d659"
      },
      "source": [
        "# Next, we're going to deactivate the hidden layers one at a time to see what happens\n",
        "\n",
        "# First, we deactivate the first layer\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  cut_first_net = ReferenceMLP(flatten=(dataset=='fashion'), \n",
        "                              hidden_layers_number=1,\n",
        "                              hidden_layers_sizes=[300])\n",
        "  cut_first_net.compile()\n",
        "  architecture_dict[\"cut first layer network \" + dataset] = cut_first_net.fit_evaluate(dataset)\n",
        "\n",
        "# And then we increase it\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  cut_sec_net = ReferenceMLP(flatten=(dataset=='fashion'), \n",
        "                              hidden_layers_number=1,\n",
        "                              hidden_layers_sizes=[100])\n",
        "  cut_sec_net.compile()\n",
        "  architecture_dict[\"cut second layer network \" + dataset] = cut_sec_net.fit_evaluate(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6530 - accuracy: 0.8385 - val_loss: 0.3611 - val_accuracy: 0.9032\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3609 - accuracy: 0.9032\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.7297 - accuracy: 0.7673 - val_loss: 0.5329 - val_accuracy: 0.8284\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5688 - accuracy: 0.8080\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6943 - accuracy: 0.8281 - val_loss: 0.3782 - val_accuracy: 0.8962\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3715 - accuracy: 0.9016\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.7710 - accuracy: 0.7492 - val_loss: 0.5815 - val_accuracy: 0.8012\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6134 - accuracy: 0.7835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZymGcOoagww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1cd2ee7-a585-450e-9f09-b714903ad786"
      },
      "source": [
        "# Finally, the last experiment involves adding a layer in various positions\n",
        "\n",
        "# First, add a layer in the begining\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  add_first_net = ReferenceMLP(flatten=(dataset=='fashion'), \n",
        "                              hidden_layers_number=3,\n",
        "                              hidden_layers_sizes=[600, 300, 100])\n",
        "  add_first_net.compile()\n",
        "  architecture_dict[\"add extra first layer network \" + dataset] = add_first_net.fit_evaluate(dataset)\n",
        "\n",
        "# Add a layer at the end\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  add_last_net = ReferenceMLP(flatten=(dataset=='fashion'), \n",
        "                              hidden_layers_number=3,\n",
        "                              hidden_layers_sizes=[300, 100, 50])\n",
        "  add_last_net.compile()\n",
        "  architecture_dict[\"add extra last layer network \" + dataset] = add_last_net.fit_evaluate(dataset)\n",
        "\n",
        "# Add a layer inbetween the existing ones\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  add_bet_net = ReferenceMLP(flatten=(dataset=='fashion'), \n",
        "                              hidden_layers_number=3,\n",
        "                              hidden_layers_sizes=[300, 200, 100])\n",
        "  add_bet_net.compile()\n",
        "  architecture_dict[\"add extra between layer network \" + dataset] = add_bet_net.fit_evaluate(dataset)\n",
        "\n",
        "# Finally, add them all at one time, leading to a 5 hidden layer network\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  add_all_net = ReferenceMLP(flatten=(dataset=='fashion'), \n",
        "                              hidden_layers_number=5,\n",
        "                              hidden_layers_sizes=[600, 300, 200, 100, 50])\n",
        "  add_all_net.compile()\n",
        "  architecture_dict[\"add three extra layers network \" + dataset] = add_all_net.fit_evaluate(dataset)\n",
        "\n",
        "# And add all layers with Dropout layers inbetween\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  add_all_net = ReferenceMLP(flatten=(dataset=='fashion'), dropout_rate=0.5,\n",
        "                              hidden_layers_number=10, \n",
        "                              hidden_layers_dropout=[1, 3, 5, 7, 9],\n",
        "                              hidden_layers_sizes=[600, None, 300, None, 200, None, 100, None, 50])\n",
        "  add_all_net.compile()\n",
        "  architecture_dict[\"add three extra layers with dropout network \" + dataset] = add_all_net.fit_evaluate(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5479 - accuracy: 0.8552 - val_loss: 0.2738 - val_accuracy: 0.9240\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2774 - accuracy: 0.9220\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.6928 - accuracy: 0.7697 - val_loss: 0.4779 - val_accuracy: 0.8362\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.8165\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.6108 - accuracy: 0.8414 - val_loss: 0.2843 - val_accuracy: 0.9218\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2926 - accuracy: 0.9188\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.7466 - accuracy: 0.7493 - val_loss: 0.4904 - val_accuracy: 0.8358\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5264 - accuracy: 0.8176\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.6303 - accuracy: 0.8308 - val_loss: 0.2919 - val_accuracy: 0.9186\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2984 - accuracy: 0.9137\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.7339 - accuracy: 0.7576 - val_loss: 0.5253 - val_accuracy: 0.8176\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5579 - accuracy: 0.8006\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.6693 - accuracy: 0.8072 - val_loss: 0.2460 - val_accuracy: 0.9304\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2513 - accuracy: 0.9274\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.7503 - accuracy: 0.7420 - val_loss: 0.5157 - val_accuracy: 0.8150\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5601 - accuracy: 0.7969\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 2.0808 - accuracy: 0.2283 - val_loss: 1.4723 - val_accuracy: 0.4588\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.4775 - accuracy: 0.4664\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.8675 - accuracy: 0.2772 - val_loss: 1.0267 - val_accuracy: 0.6020\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.0487 - accuracy: 0.5970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCniHvGeeS9R"
      },
      "source": [
        "The last thing to do is look at the results we obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbJ42Z1Zebp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfe8c35-ea59-4d38-cd5e-a43802499394"
      },
      "source": [
        "print(architecture_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'add extra first layer network mnist': [0.2773894667625427, 0.921999990940094], 'add extra first layer network fashion': [0.5108171701431274, 0.8165000081062317], 'add extra last layer network mnist': [0.29255589842796326, 0.9187999963760376], 'add extra last layer network fashion': [0.5264280438423157, 0.8176000118255615], 'add extra between layer network mnist': [0.2983740270137787, 0.9136999845504761], 'add extra between layer network fashion': [0.5579094290733337, 0.800599992275238], 'add three extra layers network mnist': [0.2512660324573517, 0.9273999929428101], 'add three extra layers network fashion': [0.5601330399513245, 0.7968999743461609], 'add three extra layers with dropout network mnist': [1.477492332458496, 0.46639999747276306], 'add three extra layers with dropout network fashion': [1.0486695766448975, 0.597000002861023]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0MAtcgfVNBs"
      },
      "source": [
        "#CNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZsBRVLM0LaW",
        "outputId": "c0af2022-86b0-40ea-e282-182a563edc85"
      },
      "source": [
        "#defining and preprocessing mnist and fashion mnist data here\n",
        "\n",
        "#MNIST\n",
        "mnist = keras.datasets.mnist\n",
        "(mnist_X_train_full, mnist_y_train_full), (mnist_X_test, mnist_y_test) = mnist.load_data()\n",
        "mnist_X_valid, mnist_X_train = mnist_X_train_full[:5000] / 255.0, mnist_X_train_full[5000:] / 255.0\n",
        "mnist_y_valid, mnist_y_train = mnist_y_train_full[:5000], mnist_y_train_full[5000:]\n",
        "\n",
        "#adding single channel of grayscale to CNN input\n",
        "mnist_X_train = mnist_X_train.reshape((mnist_X_train.shape[0], 28, 28, 1))\n",
        "mnist_X_test = mnist_X_test.reshape((mnist_X_test.shape[0], 28, 28, 1))\n",
        "mnist_X_valid = mnist_X_valid.reshape((mnist_X_valid.shape[0], 28, 28, 1))\n",
        "\n",
        "#since the taget value is an integer, using one hot encode target values as binary vactor with 1 in target index and 0 elsewhere\n",
        "#target vectors of size 10 for the 10 categories\n",
        "mnist_y_train = np_utils.to_categorical(mnist_y_train)\n",
        "mnist_y_test = np_utils.to_categorical(mnist_y_test)\n",
        "mnist_y_valid = np_utils.to_categorical(mnist_y_valid)\n",
        "\n",
        "#FASHION MNIST\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(fashion_mnist_X_train_full, fashion_mnist_y_train_full), (fashion_mnist_X_test, fashion_mnist_y_test) = fashion_mnist.load_data()\n",
        "fashion_mnist_X_valid, fashion_mnist_X_train = fashion_mnist_X_train_full[:5000] / 255.0, fashion_mnist_X_train_full[5000:] / 255.0\n",
        "fashion_mnist_y_valid, fashion_mnist_y_train = fashion_mnist_y_train_full[:5000], fashion_mnist_y_train_full[5000:]\n",
        "\n",
        "#adding single channel of grayscale to CNN input\n",
        "fashion_mnist_X_train = fashion_mnist_X_train.reshape((fashion_mnist_X_train.shape[0], 28, 28, 1))\n",
        "fashion_mnist_X_test = fashion_mnist_X_test.reshape((fashion_mnist_X_test.shape[0], 28, 28, 1))\n",
        "fashion_mnist_X_valid = fashion_mnist_X_valid.reshape((fashion_mnist_X_valid.shape[0], 28, 28, 1))\n",
        " \n",
        "#since the taget value is an integer, using one hot encode target values as binary vactor with 1 in target index and 0 elsewhere\n",
        "#target vectors of size 10 for the 10 categories\n",
        "fashion_mnist_y_train = np_utils.to_categorical(fashion_mnist_y_train)\n",
        "fashion_mnist_y_test = np_utils.to_categorical(fashion_mnist_y_test)\n",
        "fashion_mnist_y_valid = np_utils.to_categorical(fashion_mnist_y_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJS7gauF1JTP"
      },
      "source": [
        "<h3> Tuning Hyperparameters that do not change the network</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y34ArJs_0fFR"
      },
      "source": [
        "from functools import partial\n",
        "def define_model(optimizer='adam'):\n",
        "  DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "  model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD7eRnhv0sIV"
      },
      "source": [
        "sgd1=keras.optimizers.SGD(learning_rate=0.001)\n",
        "sgd2=keras.optimizers.SGD(learning_rate=0.01)\n",
        "sgd3=keras.optimizers.SGD(learning_rate=0.1)\n",
        "adagrad1=keras.optimizers.Adagrad(learning_rate=0.001)\n",
        "adagrad2=keras.optimizers.Adagrad(learning_rate=0.01)\n",
        "adagrad3=keras.optimizers.Adagrad(learning_rate=0.1)\n",
        "adam1=keras.optimizers.Adam(learning_rate=0.001)\n",
        "adam2=keras.optimizers.Adam(learning_rate=0.01)\n",
        "adam3=keras.optimizers.Adam(learning_rate=0.1)\n",
        "rmsprop1=keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "rmsprop2=keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "rmsprop3=keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "optimizer=[sgd1, sgd2, sgd3, adagrad1, adagrad2, adagrad3, adam1, adam2, adam3, rmsprop1, rmsprop2, rmsprop3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igGgnN6j0wsy"
      },
      "source": [
        "optimizer_dict={}\n",
        "for dataset in ['mnist', 'fashion']:\n",
        " for i in optimizer:\n",
        "  model=define_model(i)\n",
        "  if(dataset=='mnist'):\n",
        "    model.fit(mnist_X_train, mnist_y_train, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "    score, acc = model.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "  else:\n",
        "    model.fit(fashion_mnist_X_train, fashion_mnist_y_train, validation_data=(fashion_mnist_X_valid,fashion_mnist_y_valid))\n",
        "    score, acc = model.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "  print('Val accuracy:', acc)\n",
        "  optimizer_dict[(dataset,i)]=acc\n",
        "\n",
        "print(optimizer_dict)\n",
        "#MNIST - 98.86 accuracy --> RMSprop LR=0.01\n",
        "#Fashion MNIST - 85.57 --> RMSprop LR=0.1\n",
        "\n",
        "batch_size=[64,128,256]\n",
        "epochs=[5,10]\n",
        "epochs_bs_dict={}\n",
        "for dataset in ['mnist', 'fashion']:\n",
        " for i in batch_size:\n",
        "   for j in epochs:\n",
        "    if(dataset=='mnist'):\n",
        "      model=define_model(rmsprop2)\n",
        "      model.fit(mnist_X_train, mnist_y_train, epochs=j, batch_size=i, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "      score, acc = model.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "    else:\n",
        "      model=define_model(rmsprop3)\n",
        "      model.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=j, batch_size=i, validation_data=(fashion_mnist_X_valid,fashion_mnist_y_valid))\n",
        "      score, acc = model.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "    print('Val accuracy:', acc)\n",
        "    optimizer_dict[(dataset,\"bs \"+str(i)+\" ep \"+str(j))]=acc\n",
        "\n",
        "print(optimizer_dict)\n",
        "#MNIST - 99.39 --> bs 256 ep 10\n",
        "#fashion - 90.11 --> bs 256 ep 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEbWdkKt09r_"
      },
      "source": [
        "from functools import partial\n",
        "def define_model2(optimizer='adam', kernel_initializer='glorot_uniform', bias_initializer='zeros'):\n",
        "  DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\", kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
        "  model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFhy6gL31AHY"
      },
      "source": [
        "w1_randomNormal=tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
        "w2_zeros=tf.keras.initializers.Zeros()\n",
        "w3_glorotUniform=tf.keras.initializers.GlorotUniform()\n",
        "weights=[w1_randomNormal,w2_zeros,w3_glorotUniform]\n",
        "epochs_bs_dict={}\n",
        "for dataset in ['mnist', 'fashion']:\n",
        " for i in weights:\n",
        "   for j in weights:\n",
        "    if(dataset=='mnist'):\n",
        "      model=define_model2(rmsprop2, kernel_initializer=i, bias_initializer=j)\n",
        "      model.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "      score, acc = model.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "    else:\n",
        "      model=define_model2(rmsprop3, kernel_initializer=i, bias_initializer=j)\n",
        "      model.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid,fashion_mnist_y_valid))\n",
        "      score, acc = model.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "    print('Val accuracy:', acc)\n",
        "    optimizer_dict[(dataset,\"kernel \"+str(i)+\" bias \"+str(j))]=acc\n",
        "\n",
        "print(optimizer_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAQN3u8I1YPt"
      },
      "source": [
        "<h3> Tuning Parameters that change the network </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cb87i0t1WP-"
      },
      "source": [
        "from functools import partial\n",
        "def define_model3(optimizer='adam', default_kernel_size=3,\n",
        "                  activation='relu', padding='SAME',filter_one=64, filter_two=128, filter_three=256, dense_units_one=128, \n",
        "                  dense_units_two=64, dropout_rate=0.5):\n",
        "  DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=default_kernel_size, activation=activation, padding=\"SAME\")\n",
        "  model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=filter_one, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=filter_two),\n",
        "  DefaultConv2D(filters=filter_two),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=filter_three),\n",
        "  DefaultConv2D(filters=filter_three),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=dense_units_one, activation=activation),\n",
        "  keras.layers.Dropout(dropout_rate),\n",
        "  keras.layers.Dense(units=dense_units_two, activation=activation),\n",
        "  keras.layers.Dropout(dropout_rate),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-bF2xjH1gpO"
      },
      "source": [
        "#changing activation function \n",
        "activation_dictionary={}\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "  for i in ['tanh','selu']:\n",
        "     if(dataset=='mnist'):\n",
        "      model=define_model3(optimizer=rmsprop2, activation=i)\n",
        "      model.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "      score, acc = model.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "     else:\n",
        "      model=define_model3(optimizer=rmsprop3, activation=i)\n",
        "      model.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid,fashion_mnist_y_valid))\n",
        "      score, acc = model.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "     print('Val accuracy:', acc)\n",
        "     activation_dictionary[(dataset,i)]=acc\n",
        "\n",
        "print(activation_dictionary)\n",
        "\n",
        "#changing filter sizes\n",
        "#reducing\n",
        "filter_decrease_dictionary={}\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "     if(dataset=='mnist'):\n",
        "      model=define_model3(optimizer=rmsprop2, filter_one=16, filter_two=64, filter_three=128, dense_units_one=64, dense_units_two=16)\n",
        "      model.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "      score, acc = model.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "     else:\n",
        "      model=define_model3(optimizer=rmsprop3, filter_one=16, filter_two=64, filter_three=128, dense_units_one=64, dense_units_two=16)\n",
        "      model.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid,fashion_mnist_y_valid))\n",
        "      score, acc = model.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "     print('Val accuracy:', acc)\n",
        "     filter_decrease_dictionary[(dataset,i)]=acc\n",
        "\n",
        "#increasing\n",
        "filter_increase_dictionary={}\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "     if(dataset=='mnist'):\n",
        "      model=define_model3(optimizer=rmsprop2, filter_one=128, filter_two=256, filter_three=512, dense_units_one=256, dense_units_two=128)\n",
        "      model.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "      score, acc = model.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "     else:\n",
        "      model=define_model3(optimizer=rmsprop3, filter_one=128, filter_two=256, filter_three=512, dense_units_one=256, dense_units_two=128)\n",
        "      model.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid,fashion_mnist_y_valid))\n",
        "      score, acc = model.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "     print('Val accuracy:', acc)\n",
        "     filter_increase_dictionary[(dataset,i)]=acc\n",
        "\n",
        "print(filter_decrease_dictionary)\n",
        "print(filter_increase_dictionary)\n",
        "\n",
        "\n",
        "dropout_rate_dictionary={}\n",
        "for dataset in ['mnist', 'fashion']:\n",
        "     if(dataset=='mnist'):\n",
        "      model=define_model3(optimizer=rmsprop2, dropout_rate=0.4)\n",
        "      model.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "      score, acc = model.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "     else:\n",
        "      model=define_model3(optimizer=rmsprop3, dropout_rate=0.4)\n",
        "      model.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid,fashion_mnist_y_valid))\n",
        "      score, acc = model.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "     print('Val accuracy:', acc)\n",
        "     dropout_rate_dictionary[(dataset)]=acc\n",
        "\n",
        "print(dropout_rate_dictionary)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V1KuVn42Sv9"
      },
      "source": [
        "from functools import partial\n",
        "\n",
        "pool_dictionary={}\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "model_pool = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.AveragePooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.AveragePooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.AveragePooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "model_pool.compile(loss='categorical_crossentropy', optimizer=rmsprop2, metrics=['accuracy'])\n",
        "model_pool.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "score, acc = model_pool.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "pool_dictionary['mnist']=acc\n",
        "\n",
        "model_pool.compile(loss='categorical_crossentropy', optimizer=rmsprop3, metrics=['accuracy'])\n",
        "model_pool.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid,fashion_mnist_y_valid))\n",
        "score, acc = model_pool.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "pool_dictionary['fashion']=acc\n",
        "\n",
        "print(pool_dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS0gOAiF200A"
      },
      "source": [
        "layers_reduce_dictionary={}\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "model_layer_reduce = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "model_layer_reduce.compile(loss='categorical_crossentropy', optimizer=rmsprop2, metrics=['accuracy'])\n",
        "model_layer_reduce.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "score, acc = model_layer_reduce.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "layers_reduce_dictionary['mnist']=acc\n",
        "\n",
        "model_layer_reduce.compile(loss='categorical_crossentropy', optimizer=rmsprop3, metrics=['accuracy'])\n",
        "model_layer_reduce.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid,fashion_mnist_y_valid))\n",
        "score, acc = model_layer_reduce.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "layers_reduce_dictionary['fashion']=acc\n",
        "\n",
        "print(layers_reduce_dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz2kpngk27oC"
      },
      "source": [
        "layers_increase_dictionary={}\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "model_layer_increase = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=512),\n",
        "  DefaultConv2D(filters=512),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "model_layer_increase.compile(loss='categorical_crossentropy', optimizer=rmsprop2, metrics=['accuracy'])\n",
        "model_layer_increase.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "score, acc = model_layer_increase.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "layers_increase_dictionary['mnist']=acc\n",
        "\n",
        "model_layer_increase.compile(loss='categorical_crossentropy', optimizer=rmsprop3, metrics=['accuracy'])\n",
        "model_layer_increase.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid,fashion_mnist_y_valid))\n",
        "score, acc = model_layer_increase.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "layers_increase_dictionary['fashion']=acc\n",
        "\n",
        "print(layers_increase_dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPGP4rpuNOL9"
      },
      "source": [
        "#Task 2: Testing the Impact of Obfuscating Data by Randomly Permuting All Pixels\n",
        "To start with, we're going to apply a simple permutation of the pixel rows in the images in both datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyNu6AvuNXqe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "fa078770-6fe9-4efa-e6b5-145861689b00"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generating a random state\n",
        "rand = np.random.RandomState()\n",
        "\n",
        "perm_mnist = rand.permutation(X_train_mnist.shape[1])\n",
        "X_train_mnist_perm = X_train_mnist[:, perm_mnist]\n",
        "X_valid_mnist_perm = X_valid_mnist[:, perm_mnist]\n",
        "X_test_mnist_perm = X_test_mnist[:, perm_mnist]\n",
        "\n",
        "perm_fashion = rand.permutation(X_train_fashion.shape[1])\n",
        "X_train_fashion_perm = X_train_fashion[:, perm_fashion]\n",
        "X_valid_fashion_perm = X_valid_fashion[:, perm_fashion]\n",
        "X_test_fashion_perm = X_test_fashion[:, perm_fashion]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ny_train_mnist = y_train_mnist.T\\ny_valid_mnist = y_valid_mnist.T\\ny_test_mnist = y_test_mnist.T\\ny_train_fashion = y_train_fashion.T\\ny_valid_fashion = y_valid_fashion.T\\ny_test_fashion = y_test_fashion.T\\n\\n# Obfuscating MNIST\\nX_train_mnist_perm = obfuscate(X_train_mnist, rand)\\nX_valid_mnist_perm = obfuscate(X_valid_mnist, rand)\\nX_test_mnist_perm = obfuscate(X_test_mnist, rand)\\n\\n# Obfuscating Fashion MNIST\\nX_train_fashion_perm = obfuscate(X_train_fashion, rand)\\nX_valid_fashion_perm = obfuscate(X_valid_fashion, rand)\\nX_test_fashion_perm = obfuscate(X_test_fashion, rand)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uEGh-b5NYff"
      },
      "source": [
        "Let's take a look at what a Fashion MNIST sample looks like before and after obfuscation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "pugasDDVSmBV",
        "outputId": "9f73efb5-f103-4dcf-c308-d43a5954014f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig, axes = plt.subplots(1, 2)\n",
        "ax1 = axes[0]\n",
        "ax1.imshow(X_train_fashion[0], cmap='gray')\n",
        "ax1.set_title('Unobfuscated sample')\n",
        "ax2 = axes[1]\n",
        "ax2.imshow(X_train_fashion_perm[0], cmap='gray')\n",
        "ax2.set_title('Obfuscated sample')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HkVjxQWV351"
      },
      "source": [
        "#MLPs\n",
        "Now, we can get started with the MLPs. We will combine the best observed hyperparamater values and architectures from Task 1 to obtain the 'ideal' network for each dataset. For MNIST we will use: no initializer, SELU activation, no regularization, NAdam optimization, 10 steps per execution, and an additional layer between the existing layers in the reference network. For Fashion MNIST: random normal initialization, SELU activation, L2 regularization, NAdam optimization, 20 steps per execution, and 3 additional layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPOJgUdrXDt5"
      },
      "source": [
        "# Creating the 'ideal' MLP for MNIST\n",
        "model_mnist = keras.models.Sequential()\n",
        "model_mnist.add(keras.layers.Dense(300, input_shape=(784,), activation='selu'))\n",
        "model_mnist.add(keras.layers.Dense(200, activation='selu'))\n",
        "model_mnist.add(keras.layers.Dense(100, activation='selu'))\n",
        "model_mnist.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "model_mnist.compile(optimizer='nadam', steps_per_execution=10,\n",
        "                   loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Creating an identical MLP for obfuscated MNIST\n",
        "model_mnist_perm = keras.models.Sequential()\n",
        "model_mnist_perm.add(keras.layers.Dense(300, input_shape=(784,), activation='selu'))\n",
        "model_mnist_perm.add(keras.layers.Dense(200, activation='selu'))\n",
        "model_mnist_perm.add(keras.layers.Dense(100, activation='selu'))\n",
        "model_mnist_perm.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "model_mnist_perm.compile(optimizer='nadam', steps_per_execution=10,\n",
        "                   loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Creating the 'ideal' MLP for Fashion MNIST\n",
        "model_fashion = keras.models.Sequential()\n",
        "model_fashion.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "model_fashion.add(keras.layers.Dense(600, input_shape=(784,), activation='selu',\n",
        "                                   kernel_initializer='random_normal',\n",
        "                                   bias_initializer='random_normal',\n",
        "                                   kernel_regularizer='l2',\n",
        "                                   bias_regularizer='l2',\n",
        "                                   activity_regularizer='l2'))\n",
        "model_fashion.add(keras.layers.Dense(300, activation='selu',\n",
        "                                   kernel_initializer='random_normal',\n",
        "                                   bias_initializer='random_normal',\n",
        "                                   kernel_regularizer='l2',\n",
        "                                   bias_regularizer='l2',\n",
        "                                   activity_regularizer='l2'))\n",
        "model_fashion.add(keras.layers.Dense(200, activation='selu',\n",
        "                                   kernel_initializer='random_normal',\n",
        "                                   bias_initializer='random_normal',\n",
        "                                   kernel_regularizer='l2',\n",
        "                                   bias_regularizer='l2',\n",
        "                                   activity_regularizer='l2'))\n",
        "model_fashion.add(keras.layers.Dense(100, activation='selu',\n",
        "                                   kernel_initializer='random_normal',\n",
        "                                   bias_initializer='random_normal',\n",
        "                                   kernel_regularizer='l2',\n",
        "                                   bias_regularizer='l2',\n",
        "                                   activity_regularizer='l2'))\n",
        "model_fashion.add(keras.layers.Dense(50, activation='selu',\n",
        "                                   kernel_initializer='random_normal',\n",
        "                                   bias_initializer='random_normal',\n",
        "                                   kernel_regularizer='l2',\n",
        "                                   bias_regularizer='l2',\n",
        "                                   activity_regularizer='l2'))\n",
        "model_fashion.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "model_fashion.compile(optimizer='nadam', steps_per_execution=20,\n",
        "                   loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Creating an identical MLP for the obfuscated Fashion MNIST\n",
        "model_fashion_perm = keras.models.Sequential()\n",
        "model_fashion_perm.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "model_fashion_perm.add(keras.layers.Dense(600, input_shape=(784,), activation='selu',\n",
        "                                   kernel_initializer='random_normal',\n",
        "                                   bias_initializer='random_normal',\n",
        "                                   kernel_regularizer='l2',\n",
        "                                   bias_regularizer='l2',\n",
        "                                   activity_regularizer='l2'))\n",
        "model_fashion_perm.add(keras.layers.Dense(300, activation='selu',\n",
        "                                   kernel_initializer='random_normal',\n",
        "                                   bias_initializer='random_normal',\n",
        "                                   kernel_regularizer='l2',\n",
        "                                   bias_regularizer='l2',\n",
        "                                   activity_regularizer='l2'))\n",
        "model_fashion_perm.add(keras.layers.Dense(200, activation='selu',\n",
        "                                   kernel_initializer='random_normal',\n",
        "                                   bias_initializer='random_normal',\n",
        "                                   kernel_regularizer='l2',\n",
        "                                   bias_regularizer='l2',\n",
        "                                   activity_regularizer='l2'))\n",
        "model_fashion_perm.add(keras.layers.Dense(100, activation='selu',\n",
        "                                   kernel_initializer='random_normal',\n",
        "                                   bias_initializer='random_normal',\n",
        "                                   kernel_regularizer='l2',\n",
        "                                   bias_regularizer='l2',\n",
        "                                   activity_regularizer='l2'))\n",
        "model_fashion_perm.add(keras.layers.Dense(50, activation='selu',\n",
        "                                   kernel_initializer='random_normal',\n",
        "                                   bias_initializer='random_normal',\n",
        "                                   kernel_regularizer='l2',\n",
        "                                   bias_regularizer='l2',\n",
        "                                   activity_regularizer='l2'))\n",
        "model_fashion_perm.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "model_fashion_perm.compile(optimizer='nadam', steps_per_execution=20,\n",
        "                   loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPCzr9PQaVPs"
      },
      "source": [
        "Now, let's see how how the same network performs when trained on unobfuscated vs. obfuscated datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNnka9b4ajcu",
        "outputId": "dc314014-3130-47aa-f62a-f9ed1dce5bf7"
      },
      "source": [
        "print(\"X_train_mnist\", X_train_mnist)\n",
        "print(\"shape X_train\", X_train_fashion[0].shape)\n",
        "print(\"y_train_mnist\", y_train_mnist)\n",
        "print(\"shape X_train_perm\", X_train_fashion_perm[0].shape)\n",
        "#print(\"X_train_mnist_perm\", X_train_mnist_perm)\n",
        "print(\"y_train_mnist\", y_train_mnist)\n",
        "print(len(X_train_mnist))\n",
        "\n",
        "# Unobfuscated MNIST\n",
        "print(\"Unobfuscated MNIST\")\n",
        "model_mnist.fit(X_train_mnist, y_train_mnist, epochs=1,\n",
        "               validation_data=(X_valid_mnist, y_valid_mnist))\n",
        "model_mnist.evaluate(X_test_mnist, y_test_mnist)\n",
        "\n",
        "# Obfuscated MNIST\n",
        "print(\"Obfuscated MNIST\")\n",
        "model_mnist_perm.fit(X_train_mnist_perm, y_train_mnist, epochs=1,\n",
        "               validation_data=(X_valid_mnist_perm, y_valid_mnist))\n",
        "model_mnist_perm.evaluate(X_test_mnist_perm, y_test_mnist)\n",
        "\n",
        "# Unobfuscated Fashion MNIST\n",
        "print(\"Unobfuscated Fashion MNIST\")\n",
        "model_fashion.fit(X_train_fashion, y_train_fashion, epochs=1,\n",
        "               validation_data=(X_valid_fashion, y_valid_fashion))\n",
        "model_fashion.evaluate(X_test_fashion, y_test_fashion)\n",
        "\n",
        "# Obfuscated Fashion MNIST\n",
        "print(\"Obfuscated Fashion MNIST\")\n",
        "model_fashion_perm.fit(X_train_fashion_perm, y_train_fashion, epochs=1,\n",
        "               validation_data=(X_valid_fashion_perm, y_valid_fashion))\n",
        "model_fashion_perm.evaluate(X_test_fashion_perm, y_test_fashion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_mnist [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "shape X_train (28, 28)\n",
            "y_train_mnist [7 3 4 ... 5 6 8]\n",
            "shape X_train_perm (28, 28)\n",
            "y_train_mnist [7 3 4 ... 5 6 8]\n",
            "55000\n",
            "Unobfuscated MNIST\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2489 - accuracy: 0.9244 - val_loss: 0.1448 - val_accuracy: 0.9568\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1569 - accuracy: 0.9516\n",
            "Obfuscated MNIST\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2494 - accuracy: 0.9237 - val_loss: 0.1165 - val_accuracy: 0.9642\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1277 - accuracy: 0.9623\n",
            "Unobfuscated Fashion MNIST\n",
            "1719/1719 [==============================] - 19s 11ms/step - loss: 3.4449 - accuracy: 0.7469 - val_loss: 0.9957 - val_accuracy: 0.8004\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.0237 - accuracy: 0.7898\n",
            "Obfuscated Fashion MNIST\n",
            "1719/1719 [==============================] - 19s 11ms/step - loss: 3.5411 - accuracy: 0.7376 - val_loss: 1.3371 - val_accuracy: 0.7964\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.3610 - accuracy: 0.7789\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3609613180160522, 0.7789000272750854]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhFrE1KIWE8L"
      },
      "source": [
        "#CNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "oFCKmyYjAf6G",
        "outputId": "d3369c2b-030e-4bfc-f56a-fb9da610514c"
      },
      "source": [
        "#Creating the 'ideal' CNN for MNIST dataset using hyperparameter learnt in previous task\n",
        "from functools import partial\n",
        "\n",
        "#dropout_rate=0.4, Optimizer=RMSprop(learning_rate=0.001), epochs=10, batch_size=256\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "mnist_model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "mnist_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=0.001), metrics=['accuracy'])\n",
        "mnist_model.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "score, acc = mnist_model.evaluate(mnist_X_test, mnist_y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4f40d102b159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m   ])\n\u001b[1;32m     23\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmnist_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_X_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_y_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wywkhc-mEcBq"
      },
      "source": [
        "from functools import partial\n",
        "\n",
        "#dropout_rate=0.4, Optimizer=RMSprop(learning_rate=0.001), epochs=10, batch_size=256\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "mnist_model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "mnist_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=0.001), metrics=['accuracy'])\n",
        "#mnist_model.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "#score, acc = mnist_model.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "permuted_mnist_model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "permuted_mnist_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnoxtyxQFAty"
      },
      "source": [
        "#dropout_rate=0.5, Optimizer=RMSprop(learning_rate=0.001), epochs=10, batch_size=256\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "fashion_mnist_model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "fashion_mnist_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=0.001), metrics=['accuracy'])\n",
        "#fashion_mnist_model.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid, fashion_mnist_y_valid))\n",
        "#score, acc = fashion_mnist_model.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "\n",
        "permuted_fashion_mnist_model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=10, activation='softmax'),\n",
        "  ])\n",
        "permuted_fashion_mnist_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A6vtMafPeoC",
        "outputId": "ff0008a1-4f20-477b-9572-a9eb8b95a9b5"
      },
      "source": [
        "mnist_model.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "mnist_model.evaluate(mnist_X_test, mnist_y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "215/215 [==============================] - 14s 61ms/step - loss: 0.6340 - accuracy: 0.7941 - val_loss: 0.0695 - val_accuracy: 0.9812\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.1098 - accuracy: 0.9724 - val_loss: 0.1523 - val_accuracy: 0.9642\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0660 - accuracy: 0.9832 - val_loss: 0.0440 - val_accuracy: 0.9922\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0510 - accuracy: 0.9879 - val_loss: 0.0407 - val_accuracy: 0.9896\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0374 - accuracy: 0.9912 - val_loss: 0.0408 - val_accuracy: 0.9908\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0330 - accuracy: 0.9921 - val_loss: 0.0392 - val_accuracy: 0.9904\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0275 - accuracy: 0.9937 - val_loss: 0.0354 - val_accuracy: 0.9920\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.0687 - val_accuracy: 0.9906\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0233 - accuracy: 0.9946 - val_loss: 0.0557 - val_accuracy: 0.9906\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0222 - accuracy: 0.9952 - val_loss: 0.0404 - val_accuracy: 0.9922\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7.644179821014404, 0.9940000176429749]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akBdGTV_PjfQ",
        "outputId": "7692cd66-f6bd-49a3-ed96-13e6e8a627d4"
      },
      "source": [
        "permuted_mnist_model.fit(permuted_mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(permuted_mnist_X_valid, mnist_y_valid))\n",
        "permuted_mnist_model.evaluate(permuted_mnist_X_test, mnist_y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "215/215 [==============================] - 14s 62ms/step - loss: 0.9532 - accuracy: 0.6751 - val_loss: 0.2243 - val_accuracy: 0.9376\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.1991 - accuracy: 0.9477 - val_loss: 0.1007 - val_accuracy: 0.9726\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 13s 62ms/step - loss: 0.1236 - accuracy: 0.9685 - val_loss: 0.0798 - val_accuracy: 0.9770\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0855 - accuracy: 0.9781 - val_loss: 0.0741 - val_accuracy: 0.9802\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0686 - accuracy: 0.9825 - val_loss: 0.0994 - val_accuracy: 0.9786\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0541 - accuracy: 0.9863 - val_loss: 0.0855 - val_accuracy: 0.9818\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0464 - accuracy: 0.9886 - val_loss: 0.0890 - val_accuracy: 0.9756\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0407 - accuracy: 0.9900 - val_loss: 0.0729 - val_accuracy: 0.9828\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0349 - accuracy: 0.9913 - val_loss: 0.0615 - val_accuracy: 0.9864\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0315 - accuracy: 0.9922 - val_loss: 0.0711 - val_accuracy: 0.9868\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[23.2119197845459, 0.9829999804496765]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgpOvPO-Im_a",
        "outputId": "49e1b1df-a6eb-4ac3-dda2-2de4878f956e"
      },
      "source": [
        "results={}\n",
        "#mnist\n",
        "mnist_model.fit(mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(mnist_X_valid, mnist_y_valid))\n",
        "score, acc = mnist_model.evaluate(mnist_X_test, mnist_y_test, verbose=0)\n",
        "results['mnist']=acc\n",
        "\n",
        "\n",
        "#permuted mnist\n",
        "permuted_mnist_model.fit(permuted_mnist_X_train, mnist_y_train, epochs=10, batch_size=256, validation_data=(permuted_mnist_X_valid, mnist_y_valid))\n",
        "score, acc = permuted_mnist_model.evaluate(permuted_mnist_X_test, mnist_y_test, verbose=0)\n",
        "results['permuted_mnist']=acc\n",
        "\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "215/215 [==============================] - 16s 68ms/step - loss: 0.6534 - accuracy: 0.7863 - val_loss: 0.0889 - val_accuracy: 0.9760\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.1087 - accuracy: 0.9734 - val_loss: 0.0585 - val_accuracy: 0.9868\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 13s 59ms/step - loss: 0.0684 - accuracy: 0.9836 - val_loss: 0.0337 - val_accuracy: 0.9900\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 13s 59ms/step - loss: 0.0485 - accuracy: 0.9880 - val_loss: 0.0518 - val_accuracy: 0.9872\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0382 - accuracy: 0.9909 - val_loss: 0.0378 - val_accuracy: 0.9906\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0317 - accuracy: 0.9925 - val_loss: 0.0362 - val_accuracy: 0.9914\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0292 - accuracy: 0.9933 - val_loss: 0.0328 - val_accuracy: 0.9924\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0275 - accuracy: 0.9937 - val_loss: 0.0369 - val_accuracy: 0.9930\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0257 - accuracy: 0.9941 - val_loss: 0.0372 - val_accuracy: 0.9932\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.0447 - val_accuracy: 0.9912\n",
            "Epoch 1/10\n",
            "215/215 [==============================] - 15s 62ms/step - loss: 1.0902 - accuracy: 0.6265 - val_loss: 0.1896 - val_accuracy: 0.9440\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.1981 - accuracy: 0.9473 - val_loss: 0.1297 - val_accuracy: 0.9660\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.1234 - accuracy: 0.9691 - val_loss: 0.0827 - val_accuracy: 0.9814\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 13s 62ms/step - loss: 0.0888 - accuracy: 0.9778 - val_loss: 0.0849 - val_accuracy: 0.9776\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0685 - accuracy: 0.9826 - val_loss: 0.0906 - val_accuracy: 0.9790\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0574 - accuracy: 0.9854 - val_loss: 0.0658 - val_accuracy: 0.9854\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0476 - accuracy: 0.9877 - val_loss: 0.1078 - val_accuracy: 0.9832\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.0444 - accuracy: 0.9892 - val_loss: 0.0599 - val_accuracy: 0.9854\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0372 - accuracy: 0.9911 - val_loss: 0.0793 - val_accuracy: 0.9862\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.0373 - accuracy: 0.9910 - val_loss: 0.0817 - val_accuracy: 0.9848\n",
            "{'mnist': 0.9933000206947327, 'permuted_mnist': 0.9861000180244446}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtk4gP0mP3gm",
        "outputId": "9131c60d-a273-4853-a7a1-02cc509db9af"
      },
      "source": [
        "fashion_mnist_model.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid, fashion_mnist_y_valid))\n",
        "fashion_mnist_model.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.3009 - accuracy: 0.8986 - val_loss: 0.2656 - val_accuracy: 0.9056\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.2745 - accuracy: 0.9072 - val_loss: 0.2408 - val_accuracy: 0.9176\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.2493 - accuracy: 0.9155 - val_loss: 0.2455 - val_accuracy: 0.9110\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.2314 - accuracy: 0.9218 - val_loss: 0.2393 - val_accuracy: 0.9174\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.2138 - accuracy: 0.9280 - val_loss: 0.2472 - val_accuracy: 0.9170\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.1983 - accuracy: 0.9318 - val_loss: 0.2479 - val_accuracy: 0.9126\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.1885 - accuracy: 0.9368 - val_loss: 0.2577 - val_accuracy: 0.9192\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.1780 - accuracy: 0.9397 - val_loss: 0.3385 - val_accuracy: 0.9190\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.1723 - accuracy: 0.9428 - val_loss: 0.2420 - val_accuracy: 0.9218\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.1680 - accuracy: 0.9450 - val_loss: 0.3128 - val_accuracy: 0.9160\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[65.73126220703125, 0.8783000111579895]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZk4OtmkQC6G",
        "outputId": "840d2c7f-2a34-422a-ea09-4c3233d196f8"
      },
      "source": [
        "permuted_fashion_mnist_model.fit(permuted_fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(permuted_fashion_mnist_X_valid, fashion_mnist_y_valid))\n",
        "permuted_fashion_mnist_model.evaluate(permuted_fashion_mnist_X_test, fashion_mnist_y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "215/215 [==============================] - 15s 63ms/step - loss: 1.3396 - accuracy: 0.5080 - val_loss: 0.6418 - val_accuracy: 0.7474\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 13s 62ms/step - loss: 0.6543 - accuracy: 0.7685 - val_loss: 0.4444 - val_accuracy: 0.8362\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.4880 - accuracy: 0.8382 - val_loss: 0.3900 - val_accuracy: 0.8626\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.4180 - accuracy: 0.8614 - val_loss: 0.3188 - val_accuracy: 0.8828\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.3700 - accuracy: 0.8767 - val_loss: 0.3286 - val_accuracy: 0.8802\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.3371 - accuracy: 0.8879 - val_loss: 0.3015 - val_accuracy: 0.8930\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.3158 - accuracy: 0.8952 - val_loss: 0.3041 - val_accuracy: 0.8904\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.2887 - accuracy: 0.9010 - val_loss: 0.2846 - val_accuracy: 0.9042\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.2757 - accuracy: 0.9072 - val_loss: 0.3338 - val_accuracy: 0.8910\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 13s 60ms/step - loss: 0.2571 - accuracy: 0.9139 - val_loss: 0.3133 - val_accuracy: 0.8940\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 40.3773 - accuracy: 0.8461\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40.3773307800293, 0.8460999727249146]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "-y2jT84DJsSl",
        "outputId": "1e483404-2325-4628-8519-cf5cbe68cb45"
      },
      "source": [
        "#fashion_mnist\n",
        "fashion_mnist_model.fit(fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(fashion_mnist_X_valid, fashion_mnist_y_valid))\n",
        "score, acc = fashion_mnist_model.evaluate(fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "results['fashion_mnist']=acc\n",
        "\n",
        "#permuted fashion_mnist\n",
        "permuted_fashion_mnist_model.fit(permuted_fashion_mnist_X_train, fashion_mnist_y_train, epochs=10, batch_size=256, validation_data=(permuted_fashion_mnist_X_valid, fashion_mnist_y_valid))\n",
        "score, acc = permuted_fashion_mnist_model.evaluate(permuted_fashion_mnist_X_test, fashion_mnist_y_test, verbose=0)\n",
        "results['permuted_fashion_mnist']=acc\n",
        "\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "215/215 [==============================] - 15s 62ms/step - loss: 1.1435 - accuracy: 0.5891 - val_loss: 0.4437 - val_accuracy: 0.8420\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.5087 - accuracy: 0.8255 - val_loss: 0.3474 - val_accuracy: 0.8634\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 13s 61ms/step - loss: 0.3905 - accuracy: 0.8679 - val_loss: 0.2873 - val_accuracy: 0.8978\n",
            "Epoch 4/10\n",
            "178/215 [=======================>......] - ETA: 2s - loss: 0.3404 - accuracy: 0.8861"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-830afa1796de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fashion_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfashion_mnist_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashion_mnist_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashion_mnist_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashion_mnist_X_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashion_mnist_y_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfashion_mnist_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashion_mnist_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashion_mnist_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fashion_mnist'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNzVxke4Sl8t"
      },
      "source": [
        "#Task3: Using CNNs to tell time from images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxPrjVjN3YxK"
      },
      "source": [
        "First, we need to load the npy files that we will use as datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmbWIXl619XS",
        "outputId": "302367d6-fe47-470d-a67a-0f5738663353"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/My Drive/IDL_Assignment_2/images.npy', 'rb') as f:\n",
        "  X = np.load(f)\n",
        "with open('/content/drive/My Drive/IDL_Assignment_2/labels.npy', 'rb') as f:\n",
        "  y = np.load(f)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTfJzgIe6JZR"
      },
      "source": [
        "For a multi-class classification problem, the tuple labels suit us, but to convert this into a regression problem we can calculate the number of minutes that have passed after 12 o'clock."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Q711qn6ujm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c29411-4393-4b8e-d2bd-bb95da5eed19"
      },
      "source": [
        "def to_minutes(label):\n",
        "  #print(label)\n",
        "  #print(label[0])\n",
        "  hour = label[0]\n",
        "  minute = label[1]\n",
        "  return (60 * hour + minute)\n",
        "\n",
        "# Labels that can be used for a regression problem\n",
        "y_reg = []\n",
        "for i in y:\n",
        "  y_reg.append(to_minutes(i))\n",
        "y_reg = np.array(y_reg)\n",
        "print(y_reg)\n",
        "X_train, X_test, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0 ... 719 719 719]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkQVXwil9ZPU"
      },
      "source": [
        "\"Common-sense\" loss functions (e.g., the \"common sense\" difference between \"predicted\" 11:55 and the \"target\" 0:05 is just 10 minutes and not 11 hours and 50 minutes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7Of8zXT-nkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8471f18d-1800-42cb-cb16-152a884baccd"
      },
      "source": [
        "# Loss function\n",
        "def common_sense_loss(y_true, y_pred, regression):\n",
        "  if not regression:\n",
        "    #the labels are (hour, minute) tuples\n",
        "    # it's easier if we convert them to minutes first\n",
        "    y_true = to_minutes(y_true)\n",
        "    y_pred = to_minutes(y_pred)\n",
        "\n",
        "  # now calculate the shortest 'distance' between the two\n",
        "  if y_true <= y_pred:\n",
        "    diff = min(y_true + 720 - y_pred, y_pred - y_true)\n",
        "  else:\n",
        "    diff = min(y_pred + 720 - y_true, y_true - y_pred)\n",
        "\n",
        "  if not regression:\n",
        "    return (int((abs(diff) - abs(diff)%60)/60), abs(diff)%60)\n",
        "  else:\n",
        "    return abs(diff)\n",
        "\n",
        "\n",
        "# Accuracy metric based on the common sense loss function\n",
        "def common_sense_accuracy(y_true, y_pred, regression):\n",
        "  if not regression:\n",
        "    correct = 0\n",
        "    total = len(y_true)\n",
        "    for i in range(len(y_true)):\n",
        "      if y_true[i] == y_pred[i]:\n",
        "        correct += 1\n",
        "    return correct / total\n",
        "  \n",
        "  else:\n",
        "    loss_sum = 0\n",
        "    max_loss = 6 * 60 # the farthest from the true value a label could be is 6 hours\n",
        "    for i in range(len(y_true)):\n",
        "      loss = common_sense_loss(y_true[i], y_pred[i], regression=regression)\n",
        "      loss_sum += loss\n",
        "    loss_avg = loss_sum/len(y_true)\n",
        "    loss_percentage = loss_avg/max_loss\n",
        "    return 1 - loss_percentage\n",
        "\n",
        "print(\"Test: common sense loss between [3, 15] and [2, 55]\")\n",
        "l = common_sense_loss([3, 15], [2, 55], False)\n",
        "print(l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: common sense loss between [3, 15] and [2, 55]\n",
            "(0, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orx5cncETTc6"
      },
      "source": [
        "Time to try the various methods that exist for solving this problem. First: <p><b>Regression according to the number of minutes passed after 12 o'clock:</b> [03 : 00  y = 180]; [05 : 30  y = 330]</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqHSvDdjTg3e",
        "outputId": "09a50b3e-1a40-4dce-e656-8914e88da463"
      },
      "source": [
        "#Creating the 'ideal' CNN for MNIST dataset using hyperparameter learnt in task 1\n",
        "from functools import partial\n",
        "\n",
        "print(X[0].shape)\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "reg_model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[150, 150, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='relu'),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  keras.layers.Dense(units=64, activation='relu'),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  # The difference is here: the last dense layer has one neuron\n",
        "  # The activation function is suitable for a regression problem\n",
        "  keras.layers.Dense(units=1, activation='relu'),\n",
        "  ])\n",
        "\n",
        "# We should use MSE as an error (because regression)\n",
        "reg_model.compile(loss='mean_squared_error',\n",
        "                    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                    metrics=['mae'])\n",
        "print(y_train_reg)\n",
        "reg_model.fit(X_train, y_train_reg, epochs=10, batch_size=256,\n",
        "              validation_split=0.1)\n",
        "reg_model.evaluate(X_test, y_test_reg)\n",
        "\n",
        "y_pred_reg = reg_model.predict(X_test)\n",
        "\n",
        "total_loss = 0\n",
        "for i in range(len(y_test_reg)):\n",
        "  total_loss += common_sense_loss(y_test_reg[i], y_pred_reg[i], True)\n",
        "print(\"Average common-sense loss: \",  total_loss/len(y_test_reg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 150, 1)\n",
            "[355 232 572 ... 635 283 372]\n",
            "Epoch 1/10\n",
            "51/51 [==============================] - 83s 2s/step - loss: 31463970.0000 - mae: 983.4498 - val_loss: 44379.8516 - val_mae: 180.4045\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 81s 2s/step - loss: 66170.0234 - mae: 211.5225 - val_loss: 104489.2344 - val_mae: 263.7506\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 81s 2s/step - loss: 213342.4375 - mae: 296.5515 - val_loss: 53003.1797 - val_mae: 191.6354\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 81s 2s/step - loss: 70339.5938 - mae: 217.5448 - val_loss: 135585.3906 - val_mae: 307.6031\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 81s 2s/step - loss: 227402.0156 - mae: 346.4059 - val_loss: 82395.5859 - val_mae: 232.4516\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 81s 2s/step - loss: 77284.3047 - mae: 226.1979 - val_loss: 45413.3047 - val_mae: 181.6737\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 80s 2s/step - loss: 82126.1094 - mae: 232.0526 - val_loss: 64271.8281 - val_mae: 207.0601\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 80s 2s/step - loss: 61820.0234 - mae: 205.5012 - val_loss: 68912.1016 - val_mae: 213.5406\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 80s 2s/step - loss: 60536.6719 - mae: 204.9295 - val_loss: 67858.5312 - val_mae: 212.0863\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 80s 2s/step - loss: 56885.0586 - mae: 198.6694 - val_loss: 53143.1016 - val_mae: 191.8059\n",
            "113/113 [==============================] - 7s 65ms/step - loss: 54455.7188 - mae: 196.4718\n",
            "Average common-sense loss:  [182.27469]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-Hcrlk_GnsR"
      },
      "source": [
        "<h3> Regression for whole output (hour+minute)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP0PrGjt86Ip",
        "outputId": "26349f76-5ce4-4770-f73f-348675b5075a"
      },
      "source": [
        "#print(np.unique(labels))\n",
        "regression_label=[]\n",
        "for input in labels:\n",
        "  hour=float(input[0])\n",
        "  minute=(input[1]/60.0)\n",
        "  regression_label.append(hour+minute)\n",
        "  #print(hour+minute)\n",
        "regression_label=np.array(regression_label)\n",
        "print(len(regression_label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNhVEkq00xl6"
      },
      "source": [
        "from functools import partial\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=32, kernel_size=7, input_shape=[150, 150, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=16),\n",
        "  DefaultConv2D(filters=16),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=8, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=1, activation='sigmoid'),\n",
        "  ])\n",
        "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=0.0001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Qm2d_u5Qpo",
        "outputId": "b399b145-a17f-42fe-9ef0-cfb2d2cbb18c"
      },
      "source": [
        "print(images.shape)\n",
        "X_train_full, X_test, y_train_full_regression, y_test_regression = train_test_split(images, regression_label, test_size=0.20, random_state=42)\n",
        "X_valid, X_train = X_train_full[:4000], X_train_full[4000:]\n",
        "y_valid_regresssion, y_train_regression = y_train_full_regression[:4000], y_train_full_regression[4000:]\n",
        "print(X_train.shape, X_valid.shape)\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], 150, 150, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 150, 150, 1))\n",
        "X_valid = X_valid.reshape((X_valid.shape[0], 150, 150, 1))\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18000, 150, 150)\n",
            "(10400, 150, 150) (4000, 150, 150)\n",
            "(10400, 150, 150, 1) (3600, 150, 150, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uetnTV53_ql6",
        "outputId": "7fca6dc1-f2ec-47a5-e565-a6d0cc73015e"
      },
      "source": [
        "{i: v for i, v in enumerate(model.layers)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: <keras.layers.convolutional.Conv2D at 0x7faa28736ed0>,\n",
              " 1: <keras.layers.pooling.MaxPooling2D at 0x7faa287363d0>,\n",
              " 2: <keras.layers.convolutional.Conv2D at 0x7faa2a03ccd0>,\n",
              " 3: <keras.layers.convolutional.Conv2D at 0x7faa28740710>,\n",
              " 4: <keras.layers.pooling.MaxPooling2D at 0x7faa28740c10>,\n",
              " 5: <keras.layers.convolutional.Conv2D at 0x7faa28736110>,\n",
              " 6: <keras.layers.convolutional.Conv2D at 0x7faa286e1dd0>,\n",
              " 7: <keras.layers.pooling.MaxPooling2D at 0x7faa286e1e90>,\n",
              " 8: <keras.layers.core.flatten.Flatten at 0x7faa286e1550>,\n",
              " 9: <keras.layers.core.dense.Dense at 0x7faa286fe390>,\n",
              " 10: <keras.layers.core.dropout.Dropout at 0x7faa286febd0>,\n",
              " 11: <keras.layers.core.dense.Dense at 0x7faa286fed10>,\n",
              " 12: <keras.layers.core.dropout.Dropout at 0x7faa286fe850>,\n",
              " 13: <keras.layers.core.dense.Dense at 0x7faa28701c90>}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "636B4h8F7qj8",
        "outputId": "35a30892-601d-4d62-ae21-83b365d63575"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_valid,y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "325/325 [==============================] - 70s 214ms/step - loss: -136998100992.0000 - accuracy: 0.0013 - val_loss: -399040675840.0000 - val_accuracy: 0.0020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa2871e310>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_7m30kRncq2"
      },
      "source": [
        "Trying the multi-class approach with fewer classes. The classes are \"0\" = [00:00 - 00:30], \"1\" = [00:30 - 01:00], \"2\" = [01:00 - 01:30], etc. In total, there are 24 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4ksNIMCn5tc",
        "outputId": "5500d29b-4fc0-40c2-8fe5-4411f282a193"
      },
      "source": [
        "from tensorflow.keras import utils as np_utils\n",
        "\n",
        "def to_multi_class_few(y):\n",
        "  # Converts target to a single label identifying the \"half-an-hour bin\" the\n",
        "  # image belongs to\n",
        "  new_y = 2 * y[0]\n",
        "  if y[1] > 30:\n",
        "    new_y += 1\n",
        "  return new_y\n",
        "\n",
        "#del multi_class_few_model\n",
        "\n",
        "# Converting the labels\n",
        "y_few_class = []\n",
        "for i in y:\n",
        "  y_few_class.append(to_multi_class_few(i))\n",
        "y_few_class = np.array(y_few_class)\n",
        "# One-hot encoding the labels\n",
        "y_few_class = np_utils.to_categorical(y_few_class)\n",
        "X_train, X_test, y_train_few_class, y_test_few_class = train_test_split(X, y_few_class, test_size=0.2)\n",
        "print(y_train_few_class)\n",
        "\n",
        "# Creating the network\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='selu', padding=\"SAME\")\n",
        "multi_class_few_model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=64, kernel_size=7, input_shape=[150, 150, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=256),\n",
        "  DefaultConv2D(filters=256),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=128),\n",
        "  DefaultConv2D(filters=128),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=64),\n",
        "  DefaultConv2D(filters=64),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=32),\n",
        "  DefaultConv2D(filters=32),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=128, activation='selu'),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  keras.layers.Dense(units=64, activation='selu'),\n",
        "  keras.layers.Dropout(0.4),\n",
        "  # The output layer activation function is suitable for a classification problem\n",
        "  keras.layers.Dense(units=24, activation='softmax'),\n",
        "  ])\n",
        "\n",
        "# We should use categorical crossentropy as an error (because classification)\n",
        "multi_class_few_model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer='nadam',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "multi_class_few_model.fit(X_train, y_train_few_class, epochs=10, batch_size=32,\n",
        "              validation_split=0.1)\n",
        "multi_class_few_model.evaluate(X_test, y_test_few_class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]]\n",
            "Epoch 1/10\n",
            "405/405 [==============================] - 165s 318ms/step - loss: 4.4107 - accuracy: 0.0397 - val_loss: 3.2712 - val_accuracy: 0.0375\n",
            "Epoch 2/10\n",
            "405/405 [==============================] - 129s 319ms/step - loss: 3.4677 - accuracy: 0.0434 - val_loss: 3.2009 - val_accuracy: 0.0479\n",
            "Epoch 3/10\n",
            "405/405 [==============================] - 128s 317ms/step - loss: 3.3166 - accuracy: 0.0465 - val_loss: 3.1928 - val_accuracy: 0.0431\n",
            "Epoch 4/10\n",
            "405/405 [==============================] - 128s 317ms/step - loss: 3.2782 - accuracy: 0.0403 - val_loss: 3.1980 - val_accuracy: 0.0396\n",
            "Epoch 5/10\n",
            "405/405 [==============================] - 129s 318ms/step - loss: 3.2504 - accuracy: 0.0424 - val_loss: 3.1980 - val_accuracy: 0.0410\n",
            "Epoch 6/10\n",
            "405/405 [==============================] - 129s 319ms/step - loss: 3.2354 - accuracy: 0.0399 - val_loss: 3.1901 - val_accuracy: 0.0375\n",
            "Epoch 7/10\n",
            "405/405 [==============================] - 129s 319ms/step - loss: 3.2302 - accuracy: 0.0430 - val_loss: 3.1937 - val_accuracy: 0.0444\n",
            "Epoch 8/10\n",
            "405/405 [==============================] - 128s 317ms/step - loss: 3.2111 - accuracy: 0.0450 - val_loss: 3.1861 - val_accuracy: 0.0451\n",
            "Epoch 9/10\n",
            "405/405 [==============================] - 128s 317ms/step - loss: 3.2095 - accuracy: 0.0395 - val_loss: 3.1850 - val_accuracy: 0.0451\n",
            "Epoch 10/10\n",
            "405/405 [==============================] - 129s 319ms/step - loss: 3.2038 - accuracy: 0.0444 - val_loss: 3.1787 - val_accuracy: 0.0493\n",
            "113/113 [==============================] - 12s 104ms/step - loss: 3.1830 - accuracy: 0.0436\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.183028221130371, 0.043611109256744385]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qyM5Xj_5ZsI",
        "outputId": "3a516aaf-3558-483b-8df3-ebeedfd1ffce"
      },
      "source": [
        "# Common sense loss function for the few multi-class network\n",
        "def multi_class_common_sense(y_true, y_pred, class_num):\n",
        "  #print(\"y_true\", y_true)\n",
        "  #print(\"y_pred\", y_pred)\n",
        "  if y_true <= y_pred:\n",
        "    diff = min(y_true + class_num - y_pred, y_pred - y_true)\n",
        "  else:\n",
        "    diff = min(y_pred + class_num - y_true, y_true - y_pred)\n",
        "  return abs(diff)\n",
        "\n",
        "def multi_class_common_sense_accuracy(y_true, y_pred, class_num):\n",
        "  loss_sum = 0\n",
        "  max_loss = class_num/2 # the farthest from the true value is half a clock away\n",
        "  for i in range(len(y_true)):\n",
        "    loss = multi_class_common_sense(y_true[i], y_pred[i], class_num)\n",
        "    loss_sum += loss\n",
        "  loss_avg = loss_sum/len(y_true)\n",
        "  loss_percentage = loss_avg/max_loss\n",
        "  return 1 - loss_percentage\n",
        "\n",
        "# Evaluating on the test set with common sense loss and accuracy\n",
        "y_pred_few_class = multi_class_few_model.predict(X_test)\n",
        "# Convert to a non-one-hot encoded equivalent\n",
        "y_pred_few_class_conv = []\n",
        "for i in y_pred_few_class:\n",
        "  y_pred_few_class_conv.append(np.where(i==np.amax(i)))\n",
        "y_pred_few_class_conv = np.array(y_pred_few_class_conv)\n",
        "y_test_few_class_conv = []\n",
        "for i in y_test_few_class:\n",
        "  y_test_few_class_conv.append(np.where(i==np.amax(i)))\n",
        "y_test_few_class_conv = np.array(y_test_few_class_conv)\n",
        "\n",
        "# Calculating common sense loss\n",
        "total_loss = 0\n",
        "for i in range(len(y_test_few_class_conv)):\n",
        "  total_loss += multi_class_common_sense(y_test_few_class_conv[i], y_pred_few_class_conv[i], 24)\n",
        "print(\"Average common-sense loss in halves of an hour: \",  total_loss/len(y_test_few_class_conv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average common-sense loss in halves of an hour:  [[5.98361111]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg4ODUXrfum9"
      },
      "source": [
        "Multi-head classification: One head predicts the hours, the other the minutes. We'll use a different approach for building the network for this method: Functional API instead of Sequential API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qrdiEMzg1t-",
        "outputId": "0b3cdb3b-9f6b-4e5b-f25c-b59b246497e9"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "\n",
        "X = X.reshape(-1, 150, 150, 1)\n",
        "print(X.shape)\n",
        "\n",
        "y_hour = []\n",
        "for i in y:\n",
        "  y_hour.append(i[0])\n",
        "y_hour = np.array(y_hour)\n",
        "#y_hour = np_utils.to_categorical(y_hour)\n",
        "\n",
        "y_minute = []\n",
        "for i in y:\n",
        "  y_minute.append(i[1])\n",
        "y_minute = np.array(y_minute)\n",
        "\n",
        "X_train, X_test, y_train_hour, y_test_hour = train_test_split(X, y_hour, test_size=0.2)\n",
        "X_train, X_test, y_train_minute, y_test_minute = train_test_split(X, y_minute, test_size=0.2)\n",
        "\n",
        "print(\"X\", X.shape)\n",
        "print(\"y_hour\", y_hour.shape)\n",
        "print(\"y_minute\", y_minute.shape)\n",
        "\n",
        "#del multi_head_model\n",
        "\n",
        "inputs = Input(shape=(150, 150,1), name='inputs')\n",
        "x = DefaultConv2D(filters=64, kernel_size=7, name='64')(inputs)\n",
        "x = MaxPooling2D(pool_size=2)(x)\n",
        "x = DefaultConv2D(filters=128)(x)\n",
        "x = DefaultConv2D(filters=128)(x)\n",
        "x = MaxPooling2D(pool_size=2)(x)\n",
        "x = DefaultConv2D(filters=256)(x)\n",
        "x = DefaultConv2D(filters=256)(x)\n",
        "x = MaxPooling2D(pool_size=2)(x)\n",
        "x = Flatten()(x)\n",
        "x1 = Dense(units=64, activation='relu')(x)\n",
        "#x1 = Dropout(0.4)(x1)\n",
        "output1 = Dense(units=12, activation='softmax', name='hour_out')(x1)\n",
        "x2 = Dense(units=128, activation='relu')(x)\n",
        "#x2 = Dropout(0.4)(x2)\n",
        "x2 = Dense(units=64, activation='relu')(x2)\n",
        "#x2 = Dropout(0.4)(x2)\n",
        "output2 = Dense(1, name='minute_out')(x2)\n",
        "\n",
        "multi_head_model = Model(inputs=inputs, outputs=[output1, output2])\n",
        "\n",
        "multi_head_model.compile(loss={'hour_out': 'sparse_categorical_crossentropy', \n",
        "                    'minute_out': 'mae'},\n",
        "              optimizer='adam',\n",
        "              metrics={'hour_out': tf.metrics.SparseCategoricalAccuracy(name='acc')})\n",
        "\n",
        "multi_head_model.fit(X_train, {'hour_out': y_train_hour, 'minute_out': y_train_minute},\n",
        "                     epochs=10, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18000, 150, 150, 1)\n",
            "X (18000, 150, 150, 1)\n",
            "y_hour (18000,)\n",
            "y_minute (18000,)\n",
            "Epoch 1/10\n",
            "405/405 [==============================] - 84s 205ms/step - loss: 21.2403 - hour_out_loss: 3.0979 - minute_out_loss: 18.1424 - hour_out_acc: 0.0809 - val_loss: 18.0820 - val_hour_out_loss: 2.4853 - val_minute_out_loss: 15.5967 - val_hour_out_acc: 0.0688\n",
            "Epoch 2/10\n",
            "405/405 [==============================] - 82s 203ms/step - loss: 18.6952 - hour_out_loss: 2.4857 - minute_out_loss: 16.2096 - hour_out_acc: 0.0816 - val_loss: 17.5491 - val_hour_out_loss: 2.4857 - val_minute_out_loss: 15.0634 - val_hour_out_acc: 0.0688\n",
            "Epoch 3/10\n",
            "405/405 [==============================] - 80s 197ms/step - loss: 18.4344 - hour_out_loss: 2.4850 - minute_out_loss: 15.9494 - hour_out_acc: 0.0847 - val_loss: 17.2446 - val_hour_out_loss: 2.4856 - val_minute_out_loss: 14.7590 - val_hour_out_acc: 0.0965\n",
            "Epoch 4/10\n",
            "405/405 [==============================] - 80s 196ms/step - loss: 18.1832 - hour_out_loss: 2.4860 - minute_out_loss: 15.6971 - hour_out_acc: 0.0846 - val_loss: 17.3141 - val_hour_out_loss: 2.4856 - val_minute_out_loss: 14.8286 - val_hour_out_acc: 0.0965\n",
            "Epoch 5/10\n",
            "405/405 [==============================] - 82s 202ms/step - loss: 18.3021 - hour_out_loss: 2.4852 - minute_out_loss: 15.8169 - hour_out_acc: 0.0827 - val_loss: 17.2636 - val_hour_out_loss: 2.4857 - val_minute_out_loss: 14.7779 - val_hour_out_acc: 0.0688\n",
            "Epoch 6/10\n",
            "405/405 [==============================] - 79s 195ms/step - loss: 18.2392 - hour_out_loss: 2.4850 - minute_out_loss: 15.7541 - hour_out_acc: 0.0816 - val_loss: 17.3610 - val_hour_out_loss: 2.4858 - val_minute_out_loss: 14.8753 - val_hour_out_acc: 0.0688\n",
            "Epoch 7/10\n",
            "405/405 [==============================] - 79s 196ms/step - loss: 18.1979 - hour_out_loss: 2.4850 - minute_out_loss: 15.7129 - hour_out_acc: 0.0821 - val_loss: 17.3021 - val_hour_out_loss: 2.4856 - val_minute_out_loss: 14.8165 - val_hour_out_acc: 0.0688\n",
            "Epoch 8/10\n",
            "405/405 [==============================] - 79s 195ms/step - loss: 18.1698 - hour_out_loss: 2.4850 - minute_out_loss: 15.6848 - hour_out_acc: 0.0840 - val_loss: 17.2698 - val_hour_out_loss: 2.4857 - val_minute_out_loss: 14.7841 - val_hour_out_acc: 0.0688\n",
            "Epoch 9/10\n",
            "405/405 [==============================] - 79s 195ms/step - loss: 18.2125 - hour_out_loss: 2.4850 - minute_out_loss: 15.7275 - hour_out_acc: 0.0805 - val_loss: 17.3454 - val_hour_out_loss: 2.4857 - val_minute_out_loss: 14.8597 - val_hour_out_acc: 0.0688\n",
            "Epoch 10/10\n",
            "405/405 [==============================] - 79s 195ms/step - loss: 18.2141 - hour_out_loss: 2.4850 - minute_out_loss: 15.7291 - hour_out_acc: 0.0839 - val_loss: 17.3185 - val_hour_out_loss: 2.4856 - val_minute_out_loss: 14.8328 - val_hour_out_acc: 0.0688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0f640c6990>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OCRdJPdEBXz"
      },
      "source": [
        "Common sense loss for the multi-head."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO75PAkYFQlt",
        "outputId": "9f047645-4c1b-445b-c7d8-d71a85848a67"
      },
      "source": [
        "y_multi_head_pred = multi_head_model.predict(X_test)\n",
        "y_pred_hour, y_pred_minute = y_multi_head_pred\n",
        "\n",
        "# decoding the hours\n",
        "y_pred_hour_conv = []\n",
        "for i in y_pred_hour:\n",
        "  y_pred_hour_conv.append(np.where(i==np.amax(i)))\n",
        "y_pred_hour_conv = np.array(y_pred_few_class_conv)\n",
        "y_pred_hour_conv = np.reshape(y_pred_hour_conv, [1, 1, -1])[0][0]\n",
        "#print(y_pred_hour_conv)\n",
        "\n",
        "y_test_hour_conv = []\n",
        "for i in y_test_hour:\n",
        "  y_test_hour_conv.append(np.where(i==np.amax(i)))\n",
        "y_test_hour_conv = np.array(y_test_few_class_conv)\n",
        "y_test_hour_conv = np.reshape(y_test_hour_conv, [1, 1, -1])[0][0]\n",
        "#print(y_test_hour_conv)\n",
        "\n",
        "#print(y_test_minute)\n",
        "\n",
        "y_pred_minute = np.reshape(y_pred_minute, [1, -1])[0]\n",
        "#print(y_pred_minute)\n",
        "\n",
        "# calculating average common sense loss\n",
        "total_loss = 0\n",
        "for i in range(len(y_test_hour_conv)):\n",
        "  total_loss += to_minutes(common_sense_loss([y_test_hour_conv[i], y_test_minute[i]], [y_pred_hour_conv[i], y_pred_minute[i]], False))\n",
        "print(\"Average common-sense loss in minutes: \",  total_loss/len(y_test_hour_conv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average common-sense loss in minutes:  177.89045826223162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGgLkRmFMzgy"
      },
      "source": [
        "<h3> cyclic encoding </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzs8-0fsONWU"
      },
      "source": [
        "First, we convert time (hour and minutes) into minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "xUPj6Z0GMzIL",
        "outputId": "7d8f2eab-e5d3-473b-9227-c65e469f66af"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#figure(figsize=(8,8), dpi=80)\n",
        "\n",
        "max_value=12\n",
        "sin_time=np.sin(2*np.pi*regression_label/12)\n",
        "cos_time=np.cos(2*np.pi*regression_label/12)\n",
        "print(sin_time)\n",
        "print(cos_time)\n",
        "#df=pd.DataFrame()\n",
        "\n",
        "#df['sin_value']=sin_time\n",
        "#df['cos_value']=cos_time\n",
        "#df.sample(18000).plot.scatter('sin_value','cos_value').set_aspect('equal')\n",
        "plt.plot(sin_time,cos_time)\n",
        "y_labels=[]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.          0.          0.         ... -0.01745241 -0.01745241\n",
            " -0.01745241]\n",
            "[1.        1.        1.        ... 0.9998477 0.9998477 0.9998477]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "RG2_FUDne9Cb",
        "outputId": "bb1e45bb-ed4d-403b-cc0c-76d0fb00b594"
      },
      "source": [
        "cyclic_labels=[]\n",
        "for i in range(len(labels)):\n",
        "  entry=[]\n",
        "  entry.append(np.sin(2*np.pi*regression_label[i]/12))\n",
        "  entry.append(np.cos(2*np.pi*regression_label[i]/12))\n",
        "  cyclic_labels.append(entry)\n",
        "#print(cyclic_labels)\n",
        "plt.plot(cyclic_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff3e418c7d0>,\n",
              " <matplotlib.lines.Line2D at 0x7ff3e418cdd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPiM0qIoxTvE",
        "outputId": "49e6b6ef-88ae-4749-f960-7c9ba0600936"
      },
      "source": [
        "from functools import partial\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "model = keras.models.Sequential([\n",
        "  DefaultConv2D(filters=32, kernel_size=7, input_shape=[150, 150, 1]),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  DefaultConv2D(filters=16),\n",
        "  DefaultConv2D(filters=16),\n",
        "  keras.layers.MaxPooling2D(pool_size=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(units=8, activation='relu'),\n",
        "  keras.layers.Dropout(0.5),\n",
        "  keras.layers.Dense(units=2, activation='softmax'),  \n",
        "  ])\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras import utils as np_utils\n",
        "\n",
        "X_train_full, X_test, y_train_full_classification, y_test_classification = train_test_split(images, cyclic_labels, test_size=0.20, random_state=42)\n",
        "X_valid, X_train = X_train_full[:4000], X_train_full[4000:]\n",
        "y_valid_classification, y_train_classification = y_train_full_classification[:4000], y_train_full_classification[4000:]\n",
        "#print(y_train, y_test)\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], 150, 150, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 150, 150, 1))\n",
        "X_valid = X_valid.reshape((X_valid.shape[0], 150, 150, 1))\n",
        "print(len(y_train_classification),len(y_test_classification))\n",
        "\n",
        "y_train_classification = np_utils.to_categorical(y_train_classification)\n",
        "y_test_classification = np_utils.to_categorical(y_test_classification)\n",
        "y_valid_classification = np_utils.to_categorical(y_valid_classification)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10400 3600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8tJJl24osbR",
        "outputId": "048764a5-f3b2-4a88-d190-a4e396197995"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import Input, Model\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "  kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "\n",
        "X=images\n",
        "y=labels\n",
        "\n",
        "X = X.reshape(-1, 150, 150, 1)\n",
        "print(X.shape)\n",
        "\n",
        "y_sine = sin_time\n",
        "#for i in y:\n",
        "#  y_hour.append(i[0])\n",
        "#y_hour = np.array(y_hour)\n",
        "#y_hour = np_utils.to_categorical(y_hour)\n",
        "\n",
        "y_cos = cos_time\n",
        "#for i in y:\n",
        "#  y_minute.append(i[1])\n",
        "#y_minute = np.array(y_minute)\n",
        "\n",
        "X_train, X_test, y_train_sine, y_test_sine = train_test_split(X, y_sine, test_size=0.2)\n",
        "X_train, X_test, y_train_cos, y_test_cos = train_test_split(X, y_cos, test_size=0.2)\n",
        "\n",
        "print(\"X\", X.shape)\n",
        "print(\"y_hour\", y_sine.shape)\n",
        "print(\"y_minute\", y_cos.shape)\n",
        "\n",
        "#del multi_head_model\n",
        "\n",
        "inputs = Input(shape=(150, 150,1), name='input')\n",
        "x = DefaultConv2D(filters=16, kernel_size=3, name='16')(inputs)\n",
        "print('sghsb')\n",
        "x = DefaultConv2D(filters=32, name='32')(x)\n",
        "x = DefaultConv2D(filters=64, name='64')(x)\n",
        "x = DefaultConv2D(filters=128, name='128')(x)\n",
        "x = Flatten()(x)\n",
        "output1 = Dense(1, name='sine_out')(x)\n",
        "output2 = Dense(1, name='cos_out')(x)\n",
        "\n",
        "multi_head_model = Model(inputs=inputs, outputs=[output1, output2])\n",
        "\n",
        "multi_head_model.compile(loss={'sine_out': 'mae', \n",
        "                    'cos_out': 'mae'},\n",
        "              optimizer='adam')\n",
        "              #metrics={'hour_out': tf.metrics.SparseCategoricalAccuracy(name='acc')})\n",
        "\n",
        "multi_head_model.fit(X_train, {'sine_out': y_train_sine, 'cos_out': y_train_cos},\n",
        "                     epochs=10, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18000, 150, 150, 1)\n",
            "X (18000, 150, 150, 1)\n",
            "y_hour (18000,)\n",
            "y_minute (18000,)\n",
            "sghsb\n",
            "Epoch 1/10\n",
            "405/405 [==============================] - 104s 255ms/step - loss: 103.0579 - sine_out_loss: 51.5642 - cos_out_loss: 51.4935 - val_loss: 1.2748 - val_sine_out_loss: 0.6365 - val_cos_out_loss: 0.6383\n",
            "Epoch 2/10\n",
            "405/405 [==============================] - 103s 254ms/step - loss: 1.2596 - sine_out_loss: 0.6358 - cos_out_loss: 0.6237 - val_loss: 1.2671 - val_sine_out_loss: 0.6431 - val_cos_out_loss: 0.6240\n",
            "Epoch 3/10\n",
            "405/405 [==============================] - 105s 259ms/step - loss: 1.2047 - sine_out_loss: 0.6143 - cos_out_loss: 0.5904 - val_loss: 1.2959 - val_sine_out_loss: 0.6736 - val_cos_out_loss: 0.6223\n",
            "Epoch 4/10\n",
            "405/405 [==============================] - 105s 260ms/step - loss: 1.0813 - sine_out_loss: 0.5549 - cos_out_loss: 0.5263 - val_loss: 1.2777 - val_sine_out_loss: 0.6633 - val_cos_out_loss: 0.6144\n",
            "Epoch 5/10\n",
            "405/405 [==============================] - 103s 255ms/step - loss: 0.9324 - sine_out_loss: 0.4769 - cos_out_loss: 0.4555 - val_loss: 1.3635 - val_sine_out_loss: 0.7023 - val_cos_out_loss: 0.6612\n",
            "Epoch 6/10\n",
            "405/405 [==============================] - 105s 260ms/step - loss: 0.8097 - sine_out_loss: 0.4154 - cos_out_loss: 0.3943 - val_loss: 1.3519 - val_sine_out_loss: 0.7029 - val_cos_out_loss: 0.6489\n",
            "Epoch 7/10\n",
            "405/405 [==============================] - 105s 260ms/step - loss: 0.7086 - sine_out_loss: 0.3618 - cos_out_loss: 0.3468 - val_loss: 1.3576 - val_sine_out_loss: 0.7086 - val_cos_out_loss: 0.6490\n",
            "Epoch 8/10\n",
            "405/405 [==============================] - 105s 260ms/step - loss: 0.6349 - sine_out_loss: 0.3243 - cos_out_loss: 0.3106 - val_loss: 1.3790 - val_sine_out_loss: 0.7288 - val_cos_out_loss: 0.6501\n",
            "Epoch 9/10\n",
            "405/405 [==============================] - 103s 255ms/step - loss: 0.5811 - sine_out_loss: 0.2960 - cos_out_loss: 0.2851 - val_loss: 1.3835 - val_sine_out_loss: 0.7270 - val_cos_out_loss: 0.6565\n",
            "Epoch 10/10\n",
            "405/405 [==============================] - 105s 260ms/step - loss: 0.5418 - sine_out_loss: 0.2747 - cos_out_loss: 0.2671 - val_loss: 1.4083 - val_sine_out_loss: 0.7419 - val_cos_out_loss: 0.6664\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3e03ed690>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}